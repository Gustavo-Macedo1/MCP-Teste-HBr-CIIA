{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "217d4000",
   "metadata": {},
   "source": [
    "# 1 - Preparar as Tools para o Llama Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0eb241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.mcp import BasicMCPClient, McpToolSpec\n",
    "\n",
    "mcp_client = BasicMCPClient(\"http://127.0.0.1:8000/sse\")\n",
    "mcp_tools = McpToolSpec(client=mcp_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8503bae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_data Adiciona novos dados à tabela do tomógrafo usando uma consulta SQL INSERT.\n",
      "\n",
      "Argumentos:\n",
      "    query (str): query SQL INSERT seguindo o seguinte formato:\n",
      "        INSERT INTO tomografo (nomePaciente, idade, resultados)\n",
      "        VALUES ('João Silva', 45, 'Glaucoma')\n",
      "    \n",
      "Esquema:\n",
      "    - nomePaciente: campo de texto (exigido)\n",
      "    - idade: campo de inteiro (exigido)\n",
      "    - resultados: campo de texto (exigido)\n",
      "    Observação: O campo 'idExame' é gerado automaticamente.\n",
      "\n",
      "Retorno:\n",
      "    bool: True se os dados foram inseridos corretamente, False caso contrário\n",
      "\n",
      "Exemplo:\n",
      "    >>> query = '''\n",
      "    ... INSERT INTO tomografo (nomePaciente, idade, resultados)\n",
      "    ... VALUES ('Alice Guerra', 25, 'Retinopatia diabética')\n",
      "    ... '''\n",
      "    >>> add_data(query)\n",
      "    True\n",
      "\n",
      "read_data Lê dados da tabela tomografo usando uma query SQL SELECT.\n",
      "\n",
      "Argumentos:\n",
      "    query (str, optional): SQL SELECT query. O comportamento default é: \"SELECT * FROM tomografo;\".\n",
      "        Exemplos:\n",
      "        - \"SELECT * FROM tomografo\"\n",
      "        - \"SELECT nomePaciente, idade FROM tomografo WHERE idade > 25\"\n",
      "        - \"SELECT * FROM tomografo ORDER BY idade DESC\"\n",
      "\n",
      "Retorna:\n",
      "    list: Uma lista de tuplas contento os resultados da query.\n",
      "          Para uma query default, o formato da tupla é (idExame, nomePaciente, idade, resultados)\n",
      "          \n",
      "\n",
      "Exemplo:\n",
      "    >>> # Leia todos os registros\n",
      "    >>> read_data()\n",
      "    [(1, 'João Silva', 45, 'Glaucoma'), (2, 'Alice Guerra', 25, 'Retinopatia diabética')]\n",
      "    \n",
      "    >>> # Leia com uma query específica\n",
      "    >>> read_data(\"SELECT nomePaciente, resultados FROM tomografo WHERE idade < 30\")\n",
      "    [('João Silva', 'Glaucoma')]\n",
      "\n",
      "erase_data Remove registros da tabela tomografo usando uma query SQL SELECT.\n",
      "\n",
      "Argumentos:\n",
      "    query (str, opcional): SQL DELETE query. \n",
      "        Exemplos:\n",
      "        - \"DELETE FROM tomografo WHERE nomePaciente=\"Alice Guerra\"\"\n",
      "        - \"DELETE FROM tomografo WHERE idade > 25\"\n",
      "\n",
      "Retorna:\n",
      "    bool: True se os dados foram inseridos corretamente, False caso contrário\n",
      "          \n",
      "\n",
      "Exemplo:\n",
      "    >>> # Apague o registro do paciente João Silva, de 45 anos.\n",
      "    >>> query = '''\n",
      "    ... DELETE FROM tomografo\n",
      "    ... WHERE nomePaciente=\"João Silva\" AND idade=45;\n",
      "    ... '''\n",
      "    >>> erase_data(query)\n",
      "    True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tools = await mcp_tools.to_tool_list_async()\n",
    "for tool in tools:\n",
    "    print(tool.metadata.name, tool.metadata.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07723cde",
   "metadata": {},
   "source": [
    "# 2 - Construir o Agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8bebc532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ea45382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import Settings\n",
    "\n",
    "llm = Ollama(model=\"qwen3:4b\", request_timeout=120)\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4cfc5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "Você é um assistente para chamada de ferramentas.\n",
    "\n",
    "Antes de ajudar um usuário, você deve trabalhar com ferramentas \n",
    "para interagir com nossa base de dados.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c8e326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.mcp import McpToolSpec\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "\n",
    "async def get_agent(tools: McpToolSpec):\n",
    "    tools = await tools.to_tool_list_async()\n",
    "    agent = FunctionAgent(\n",
    "        name=\"Agente HBr\",\n",
    "        description=\"Um agente que trabalha com a base de dados do tomógrafo.\",\n",
    "        tools=tools,\n",
    "        llm=llm,\n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "    )\n",
    "\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2264569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import (\n",
    "    FunctionAgent, \n",
    "    ToolCallResult, \n",
    "    ToolCall)\n",
    "\n",
    "from llama_index.core.workflow import Context\n",
    "\n",
    "async def handle_user_message(\n",
    "    message_content: str,\n",
    "    agent: FunctionAgent,\n",
    "    agent_context: Context,\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    handler = agent.run(message_content, ctx=agent_context)\n",
    "    async for event in handler.stream_events():\n",
    "        if verbose and type(event) == ToolCall:\n",
    "            print(f\"Calling tool {event.tool_name} with kwargs {event.tool_kwargs}\")\n",
    "        elif verbose and type(event) == ToolCallResult:\n",
    "            print(f\"Tool {event.tool_name} returned {event.tool_output}\")\n",
    "\n",
    "    response = await handler\n",
    "    return str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b557819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.mcp import BasicMCPClient, McpToolSpec\n",
    "\n",
    "\n",
    "mcp_client = BasicMCPClient(\"http://127.0.0.1:8000/sse\")\n",
    "mcp_tool = McpToolSpec(client=mcp_client)\n",
    "\n",
    "# get the agent\n",
    "agent = await get_agent(tools=mcp_tool)\n",
    "\n",
    "# create the agent context\n",
    "agent_context = Context(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21e023af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bem vindo ao servidor MCP de teste da HBr - CIIA!\n",
      "===================================================\n",
      "\n",
      "Insira abaixo seus comandos. Para sair, digite \"sair\".\n",
      "\n",
      "\n",
      " Você: Leia todos os registros da tabela tomografo\n"
     ]
    },
    {
     "ename": "ResponseError",
     "evalue": "memory layout cannot be allocated (status code: 500)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResponseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Você: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m handle_user_message(user_message, agent, agent_context, verbose=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAgente CIIA: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mhandle_user_message\u001b[39m\u001b[34m(message_content, agent, agent_context, verbose)\u001b[39m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m verbose \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(event) == ToolCallResult:\n\u001b[32m     19\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTool \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent.tool_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m returned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent.tool_output\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m handler\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gustavo\\Desktop\\HBR\\Teste MCP\\venv\\Lib\\site-packages\\workflows\\workflow.py:439\u001b[39m, in \u001b[36mWorkflow.run.<locals>._run_workflow\u001b[39m\u001b[34m(ctx)\u001b[39m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exception_raised:\n\u001b[32m    436\u001b[39m     \u001b[38;5;66;03m# cancel the stream\u001b[39;00m\n\u001b[32m    437\u001b[39m     ctx.write_event_to_stream(StopEvent())\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exception_raised\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m we_done:\n\u001b[32m    442\u001b[39m     \u001b[38;5;66;03m# cancel the stream\u001b[39;00m\n\u001b[32m    443\u001b[39m     ctx.write_event_to_stream(StopEvent())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\tasks.py:304\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    302\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    303\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    306\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gustavo\\Desktop\\HBR\\Teste MCP\\venv\\Lib\\site-packages\\workflows\\context\\context.py:822\u001b[39m, in \u001b[36mContext._step_worker\u001b[39m\u001b[34m(self, name, step, config, verbose, run_id, worker_id, resource_manager)\u001b[39m\n\u001b[32m    813\u001b[39m \u001b[38;5;28mself\u001b[39m.write_event_to_stream(\n\u001b[32m    814\u001b[39m     StepStateChanged(\n\u001b[32m    815\u001b[39m         name=name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    819\u001b[39m     )\n\u001b[32m    820\u001b[39m )\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m     new_ev = \u001b[38;5;28;01mawait\u001b[39;00m instrumented_step(**kwargs)\n\u001b[32m    823\u001b[39m     kwargs.clear()\n\u001b[32m    824\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# exit the retrying loop\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gustavo\\Desktop\\HBR\\Teste MCP\\venv\\Lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:386\u001b[39m, in \u001b[36mDispatcher.span.<locals>.async_wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    378\u001b[39m \u001b[38;5;28mself\u001b[39m.span_enter(\n\u001b[32m    379\u001b[39m     id_=id_,\n\u001b[32m    380\u001b[39m     bound_args=bound_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    383\u001b[39m     tags=tags,\n\u001b[32m    384\u001b[39m )\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m.event(SpanDropEvent(span_id=id_, err_str=\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gustavo\\Desktop\\HBR\\Teste MCP\\venv\\Lib\\site-packages\\llama_index\\core\\agent\\workflow\\base_agent.py:390\u001b[39m, in \u001b[36mBaseWorkflowAgent.run_agent_step\u001b[39m\u001b[34m(self, ctx, ev)\u001b[39m\n\u001b[32m    387\u001b[39m user_msg_str = \u001b[38;5;28;01mawait\u001b[39;00m ctx.store.get(\u001b[33m\"\u001b[39m\u001b[33muser_msg_str\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    388\u001b[39m tools = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_tools(user_msg_str \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m agent_output = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.take_step(\n\u001b[32m    391\u001b[39m     ctx,\n\u001b[32m    392\u001b[39m     ev.input,\n\u001b[32m    393\u001b[39m     tools,\n\u001b[32m    394\u001b[39m     memory,\n\u001b[32m    395\u001b[39m )\n\u001b[32m    397\u001b[39m ctx.write_event_to_stream(agent_output)\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m agent_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gustavo\\Desktop\\HBR\\Teste MCP\\venv\\Lib\\site-packages\\llama_index\\core\\agent\\workflow\\function_agent.py:120\u001b[39m, in \u001b[36mFunctionAgent.take_step\u001b[39m\u001b[34m(self, ctx, llm_input, tools, memory)\u001b[39m\n\u001b[32m    115\u001b[39m ctx.write_event_to_stream(\n\u001b[32m    116\u001b[39m     AgentInput(\u001b[38;5;28minput\u001b[39m=current_llm_input, current_agent_name=\u001b[38;5;28mself\u001b[39m.name)\n\u001b[32m    117\u001b[39m )\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.streaming:\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     last_chat_response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_streaming_response(\n\u001b[32m    121\u001b[39m         ctx, current_llm_input, tools\n\u001b[32m    122\u001b[39m     )\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    124\u001b[39m     last_chat_response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_response(current_llm_input, tools)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gustavo\\Desktop\\HBR\\Teste MCP\\venv\\Lib\\site-packages\\llama_index\\core\\agent\\workflow\\function_agent.py:75\u001b[39m, in \u001b[36mFunctionAgent._get_streaming_response\u001b[39m\u001b[34m(self, ctx, current_llm_input, tools)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# last_chat_response will be used later, after the loop.\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# We initialize it so it's valid even when 'response' is empty\u001b[39;00m\n\u001b[32m     74\u001b[39m last_chat_response = ChatResponse(message=ChatMessage())\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m last_chat_response \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[32m     76\u001b[39m     tool_calls = \u001b[38;5;28mself\u001b[39m.llm.get_tool_calls_from_response(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     77\u001b[39m         last_chat_response, error_on_no_tool_call=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     78\u001b[39m     )\n\u001b[32m     79\u001b[39m     raw = (\n\u001b[32m     80\u001b[39m         last_chat_response.raw.model_dump()\n\u001b[32m     81\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(last_chat_response.raw, BaseModel)\n\u001b[32m     82\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m last_chat_response.raw\n\u001b[32m     83\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gustavo\\Desktop\\HBR\\Teste MCP\\venv\\Lib\\site-packages\\llama_index\\core\\llms\\callbacks.py:89\u001b[39m, in \u001b[36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_async_llm_chat.<locals>.wrapped_gen\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     87\u001b[39m last_response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m f_return_val:\n\u001b[32m     90\u001b[39m         dispatcher.event(\n\u001b[32m     91\u001b[39m             LLMChatInProgressEvent(\n\u001b[32m     92\u001b[39m                 messages=messages,\n\u001b[32m   (...)\u001b[39m\u001b[32m     95\u001b[39m             )\n\u001b[32m     96\u001b[39m         )\n\u001b[32m     97\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m cast(ChatResponse, x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gustavo\\Desktop\\HBR\\Teste MCP\\venv\\Lib\\site-packages\\llama_index\\llms\\ollama\\base.py:483\u001b[39m, in \u001b[36mOllama.astream_chat.<locals>.gen\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    480\u001b[39m seen_tool_calls = \u001b[38;5;28mset\u001b[39m()\n\u001b[32m    481\u001b[39m all_tool_calls = []\n\u001b[32m--> \u001b[39m\u001b[32m483\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[32m    484\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m r[\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    485\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gustavo\\Desktop\\HBR\\Teste MCP\\venv\\Lib\\site-packages\\ollama\\_client.py:741\u001b[39m, in \u001b[36mAsyncClient._request.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    740\u001b[39m   \u001b[38;5;28;01mawait\u001b[39;00m e.response.aread()\n\u001b[32m--> \u001b[39m\u001b[32m741\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m r.aiter_lines():\n\u001b[32m    744\u001b[39m   part = json.loads(line)\n",
      "\u001b[31mResponseError\u001b[39m: memory layout cannot be allocated (status code: 500)"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Bem vindo ao servidor MCP de teste da HBr - CIIA!\\n===================================================\\n\\nInsira abaixo seus comandos. Para sair, digite \\\"sair\\\".\\n\"\"\")\n",
    "\n",
    "while True:\n",
    "    user_message = input(\"Digite a sua mensagem: \")\n",
    "\n",
    "    if (user_message.lower() == \"sair\") :\n",
    "        break\n",
    "\n",
    "    print(f\"\\n Você: {user_message}\")\n",
    "    response = await handle_user_message(user_message, agent, agent_context, verbose=True)\n",
    "    print(f\"\\nAgente CIIA: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6a5c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
